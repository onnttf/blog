name: Backup Discussion

on:
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  backup:
    runs-on: ubuntu-latest
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      OWNER: ${{ github.repository_owner }}
      REPO: ${{ github.event.repository.name }}

    steps:
      - name: Checkout discussion.json
        uses: actions/checkout@v4

      - name: Fetch, process, and save discussions
        run: |
          echo "Fetching discussions from GitHub API..."

          discussions=$(gh api graphql --paginate --slurp -f query='
            query($owner: String!, $repo: String!, $endCursor: String) {
              repository(owner: $owner, name: $repo) {
                discussions(first: 100, after: $endCursor) {
                  nodes {
                    id
                    title
                    body
                    number
                    labels(first: 10) { nodes { id name url } }
                    category { id name slug emoji emojiHTML }
                    author { login }
                    authorAssociation
                    createdAt
                    updatedAt
                    repository { id url }
                    url
                  }
                  pageInfo {
                    hasNextPage
                    endCursor
                  }
                }
              }
            }' -F owner=$OWNER -F repo=$REPO | jq '
            [.[].data.repository.discussions.nodes[]]
            | map(select(.authorAssociation == "OWNER"))
            | map(select(.category.slug == "announcements" or .category.slug == "show-and-tell"))
            | sort_by(.updatedAt) | reverse
            | unique_by(.id)
            // []'
          )

          num_discussions=$(echo "$discussions" | jq length)
          echo "Fetched $num_discussions discussions"

          if [ "$num_discussions" -eq 0 ]; then
            echo "No discussions found, exiting..."
            exit 1
          fi

          # Merge with existing data if discussion.json exists
          if [ -f "discussion.json" ]; then
            echo "Merging with existing discussions..."

            createdAtMap=$(jq 'map({(.id): .createdAt}) | add' "discussion.json")
            discussions=$(jq --argjson createdAtMap "$createdAtMap" '
              map(
                if $createdAtMap[.id] then
                  .createdAt = $createdAtMap[.id]
                else
                  .
                end
              )
            ' <<< "$discussions")

            echo "Merged existing data"
          fi

          # Add file paths to discussions
          discussions=$(echo "$discussions" | jq '
            map(
              . + {
                jsonFilePath: ("discussions/" + (.number | tostring) + "-" + (.id | tostring) + ".json"),
                markdownFilePath: (
                  if .category.slug == "announcements" then
                    "announcements/" + (.number | tostring) + "-" + (.id | tostring) + ".md"
                  else
                    (.createdAt | fromdate | strftime("%Y")) + "/" +
                    ((.createdAt | fromdate | strftime("%m") | tonumber) | tostring) + "/" +
                    (.number | tostring) + "-" + (.id | tostring) + ".md"
                  end
                )
              }
            )
          ')

          # Calculate the MD5 hash of the original discussion.json (before processing)
          if [ -f "discussion.json" ]; then
            original_md5=$(md5sum discussion.json | awk '{ print $1 }')
          else
            original_md5=""
          fi

          # Save the processed discussions to the file
          echo "$discussions" > discussion.json
          echo "Backup completed, saved discussions to discussion.json"

          # Calculate the MD5 hash after processing and saving the new content
          new_md5=$(md5sum discussion.json | awk '{ print $1 }')

          # Compare the original and new MD5 hashes to check if the file changed
          if [ "$original_md5" == "$new_md5" ]; then
            echo "discussion.json has not changed. Exiting job."
            exit 0
          fi

          echo "discussion.json has changed"

          # Initialize TOC content as a table
          toc_title="# Table of Contents\n\n"
          toc_header="| Title | Labels | Last Updated |\n| ----- | ------ | --------- |\n"
          toc_rows=""

          # Clean up all files except discussion.json
          echo "Cleaning up all files except discussion.json..."
          find . -type f ! -name "discussion.json" ! -path "*/.*" -mindepth 1 -print0 | xargs -0 rm -f
          find . -type d ! -path "*/.*" -mindepth 1 -print0 | xargs -0 rm -rf
          echo "Cleanup completed."

          # Write the README.md file first
          echo "# blog" > README.md
          echo "" >> README.md
          echo "## Table of Contents" >> README.md
          echo "" >> README.md
          echo "| Title | Labels | Last Updated |" >> README.md
          echo "| ----- | ------ | ------------ |" >> README.md

          # Traverse discussions and write to JSON and Markdown files
          echo "Writing discussions to individual files..."
          jq -c '.[]' <<< "$discussions" | while read -r discussion; do
            # 1. Extract variables
            jsonFilePath=$(echo "$discussion" | jq -r '.jsonFilePath')
            markdownFilePath=$(echo "$discussion" | jq -r '.markdownFilePath')
            title=$(echo "$discussion" | jq -r '.title')
            body=$(echo "$discussion" | jq -r '.body')

            # 2. Write discussion data to individual JSON file
            mkdir -p $(dirname "$jsonFilePath")
            echo "$discussion" > "$jsonFilePath"
            echo "Written discussion to $jsonFilePath"

            # 3. Write Markdown content to the respective Markdown file
            mkdir -p $(dirname "$markdownFilePath")
            # Use printf to write markdown content more reliably
            printf "# %s\n\n%s\n" "$title" "$body" > "$markdownFilePath"
            echo "Written markdown to $markdownFilePath"
            
            # 4. Collect TOC data and write each entry
            url=$(echo "$discussion" | jq -r '.url')
            labels=$(echo "$discussion" | jq -r '.labels.nodes | map(.name + " (" + .url + ")") | join(", ") // ""')
            updatedAt=$(echo "$discussion" | jq -r '.updatedAt')
            # Write TOC row directly into README.md
            echo "| [$title]($url) | $labels | $updatedAt |" >> README.md
          done
          
          echo "" >> README.md

      - name: Commit and Push Changes
        run: |
          echo "Starting the commit and push process..."

          # Configure Git user for commit
          echo "Configuring Git user for commit..."
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Add the necessary files to the staging area
          echo "Staging changes for commit..."
          git add README.md discussion.json discussions announcements $(find . -type d -regex './[0-9]+' -exec echo {} \;)

          # Check if there are changes to commit
          if git diff --cached --quiet; then
            echo "No changes to commit. Skipping commit and push."
            exit 0
          fi

          # Commit the changes
          echo "Committing changes to the repository..."
          git commit -m "chore: back up discussions"

          # Push the changes to the remote repository
          echo "Pushing changes to the remote repository..."
          git push

          echo "Changes committed and pushed successfully."
